{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HAR Binary Classifier - Sitting vs Standing\n",
        "\n",
        "This classifier distinguishes between sitting and standing poses using the MPII Human Pose Dataset."
      ],
      "metadata": {
        "id": "21pTmRGHvssg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It allows users to upload their own photos and predicts whether the image contains someone either sitting or standing, and providing a confidence score."
      ],
      "metadata": {
        "id": "eZJi8XvEweDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The code:**\n",
        "\n",
        "This block checks if you're in Google Colab, installs the required fastbook library, and sets up the basic environment for running fastai."
      ],
      "metadata": {
        "id": "Vxz-lohYea1m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P_xBmUvDctsk"
      },
      "outputs": [],
      "source": [
        "# 1. Setup and Imports\n",
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This imports all the necessary functions and classes from fastbook and fastai's vision module that you'll need for image processing and deep learning"
      ],
      "metadata": {
        "id": "YgaO1TEBlBtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Main Imports\n",
        "from fastbook import *\n",
        "from fastai.vision.all import *"
      ],
      "metadata": {
        "id": "2ypJFQipdPAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This downloads the MPII dataset..."
      ],
      "metadata": {
        "id": "ZUxW-F6VxHqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Setup\n",
        "path = untar_data(URLs.MPII)/'images'  # Changed from PETS to MPII dataset"
      ],
      "metadata": {
        "id": "Uws16YjgdZGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a function that labels images as sitting returning True if the image shows a sitting pose based on filename metadata. DOUBLE CHEKC MPII LABELLING SCHEME."
      ],
      "metadata": {
        "id": "yiCqTjRX3PPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Label Function\n",
        "def is_sitting(x):\n",
        "    \"\"\"Returns True if the image shows a sitting pose based on filename metadata\"\"\"\n",
        "    # You'll need to adjust this based on MPII's labeling scheme\n",
        "    return 'sit' in str(x).lower()"
      ],
      "metadata": {
        "id": "fOEUaYjH3ONH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "added>>>"
      ],
      "metadata": {
        "id": "JZ_Beizo4QVa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Data Loading with Augmentation\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path,\n",
        "    get_image_files(path),\n",
        "    valid_pct=0.2,\n",
        "    seed=42,\n",
        "    label_func=is_sitting,\n",
        "    item_tfms=Resize(224),\n",
        "    batch_tfms=[\n",
        "        *aug_transforms(flip_vert=False),  # No vertical flips for human poses\n",
        "        Normalize.from_stats(*imagenet_stats)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "i65xKCNk4SmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "added>>>"
      ],
      "metadata": {
        "id": "BVmNoChe4gSN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Model Creation & Training\n",
        "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(3)  # Training for more epochs due to complexity"
      ],
      "metadata": {
        "id": "HI2p0Cm74j-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "added>>>"
      ],
      "metadata": {
        "id": "m6xBfHLt4ygl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. File Upload Interface\n",
        "uploader = widgets.FileUpload()\n",
        "uploader"
      ],
      "metadata": {
        "id": "WpcOGMad40lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "added>>>"
      ],
      "metadata": {
        "id": "WrMjXK6w45z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Prediction\n",
        "def predict_pose(img_data):\n",
        "    img = PILImage.create(img_data)\n",
        "    is_sitting,_,probs = learn.predict(img)\n",
        "    print(f\"Is this person sitting?: {is_sitting}\")\n",
        "    print(f\"Probability of sitting: {probs[1].item():.6f}\")\n",
        "    return is_sitting, probs"
      ],
      "metadata": {
        "id": "8AAPKhcJ49lY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "added>>>"
      ],
      "metadata": {
        "id": "DqjG1AUd5GdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if uploader.data:\n",
        "    predict_pose(uploader.data[0])"
      ],
      "metadata": {
        "id": "gx5su-xF5Ifd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----"
      ],
      "metadata": {
        "id": "cvC5ObiU5M6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "YMViWMsM5Pzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HOhQHknN5Pse"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates the data loaders that will feed images to the model, splitting data into training (80%) and validation (20%) sets, and resizing all images to 224x224 pixels."
      ],
      "metadata": {
        "id": "5flmwulMxLnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Data Loading\n",
        "dls = ImageDataLoaders.from_name_func(\n",
        "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
        "    label_func=is_cat, item_tfms=Resize(224))"
      ],
      "metadata": {
        "id": "g53mtTE5d22y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a vision model using ResNet34 architecture and fine-tunes it for one epoch on your dataset."
      ],
      "metadata": {
        "id": "JA33Za7dxS6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Model Creation & Training\n",
        "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(1)"
      ],
      "metadata": {
        "id": "4a_MVTKxtxrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This block creates a file upload widget"
      ],
      "metadata": {
        "id": "incds8frt0tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. File Upload (separate cell)\n",
        "uploader = widgets.FileUpload()\n",
        "uploader"
      ],
      "metadata": {
        "id": "towHdJ9ct136"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Then handle making predictions on uploaded images."
      ],
      "metadata": {
        "id": "xHsCxSajuSwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Prediction (separate cell)\n",
        "img = PILImage.create(uploader.data[0])\n",
        "is_cat,_,probs = learn.predict(img)\n",
        "print(f\"Is this a cat?: {is_cat}.\")\n",
        "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
      ],
      "metadata": {
        "id": "mymuliCvuXgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4fc4f64d-8a9a-42a4-f529-8ac821425697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is this a cat?: False.\n",
            "Probability it's a cat: 0.062023\n"
          ]
        }
      ]
    }
  ]
}
